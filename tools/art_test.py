#
# @author:charlotte.Song
# @file: lsvt_test.py
# @Date: 2019/3/7 15:09
# @description:
# -*- coding: utf-8 -*-
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import numpy as np
import argparse
import torch
import mmcv
from mmcv.runner import load_checkpoint, parallel_test, obj_from_dict, parallel_test_art
from mmcv.parallel import scatter, collate, MMDataParallel
from mmdet import datasets
from mmdet.datasets import build_dataloader
from mmdet.models import build_detector, detectors
from mmdet.core import tensor2imgs, get_classes
import os
import cv2
import os.path as osp
from collections import OrderedDict
from postmodule.post_processor import PostProcessor
import json


""" test augmentation: rescale + flip """


def _data_func(data, device_id):
    data = scatter(collate([data], samples_per_gpu=1), [device_id])[0]
    return dict(return_loss=False, rescale=True, **data)

def parse_args():
    parser = argparse.ArgumentParser(description='MMDet text for ArT')
    parser.add_argument('config', help='test config file parser')
    parser.add_argument('checkpoint', help='checkpoint file')
    parser.add_argument('test_config', type=str,
                        help='the path of test setting file(json).')
    parser.add_argument(
        '--gpus', default=1, type=int)
    parser.add_argument(
        '--proc_per_gpu',
        default=1,
        type=int,
        help='Number of processes per GPU')
    parser.add_argument('--out', help='output result file')
    parser.add_argument(
        '--eval',
        type=str,
        nargs='+',
        choices=['proposal', 'proposal_fast', 'bbox', 'segm', 'keypoints'],
        help='eval types')
    parser.add_argument('--show', action='store_true', help='show result')
    parser.add_argument('--save_json', type=str, default=None,
                        help=' the file of result json.')
    parser.add_argument('--show_path', type=str, default=None,
                        help=' the path of store files')
    parser.add_argument('--debug', action='store_true', help='show debug')
    parser.add_argument('--gt_ann_path', type=str, default=None)
    args = parser.parse_args()
    return args


def single_test(model, data_loader, show=False):
    """ use img_meta to get ori_shape, img_shape,
        and flip.
    """
    model.eval()
    results = []
    dataset = data_loader.dataset
    prog_bar = mmcv.ProgressBar(len(dataset))
    for i, data in enumerate(data_loader):
        with torch.no_grad():
            result = model(return_loss=False, rescale=not show, **data)
        results.append(result)

        if show:
            model.module.show_result(data, result, dataset.img_norm_cfg,
                                     dataset=dataset.CLASSES)
        batch_size = data['img'].size(0)
        for _ in range(batch_size):
            prog_bar.update()
    return results


def single_test_json(model, data_loader, post_processor,
                     save_json_file, show=True, show_path=None, debug_f=True,
                     gt_ann_path=None):
    """
    :param model: model
    :param data_loader: data_loader
    :param post_processor:  use this to generate bbox from mask
    :param save_json_file:  the path of json file.
    :return:
    """
    # first get the pred, then get the bboxes from masks
    # use post_processor to filter the bboxes and then save in json file.
    # masks are generated by a set of data augmentation functions.
    model.eval()
    # get the img_infos from dataset,
    dataset = data_loader.dataset
    img_prefix = dataset.img_prefix
    img_norm_cfg = dataset.img_norm_cfg
    prog_bar = mmcv.ProgressBar(len(dataset))
    if debug_f:
        assert osp.isfile(gt_ann_path)
        with open(gt_ann_path, 'r', encoding='utf-8') as f:
            eval_gt_annotations = json.loads(f.read(), object_pairs_hook=OrderedDict)
    imgs_bboxes_results = {}

    if show and (show_path is not None and not osp.isdir(show_path)):
        os.mkdir(show_path)

    for i, data in enumerate(data_loader):
        """ get the name, height, width from data['img_meta'] 
            for multi-scale test, img_meta contains several img_meta
        """
        with torch.no_grad():
            # can change this to True.
            result = model(return_loss=False, rescale=True, **data)
        # deal with the mask and post processing here.
        # as masks are fit to the original imgs, just reload the original imgs
        #
        if isinstance(result, tuple):
            bbox_result, segm_result = result
        else:
            bbox_result, segm_result = result, None
        img_tensor = data['img'][0]     # for aug test data['img'] is a list.
        img_metas = data['img_meta'][0].data[0]  # datacontainer, return ._data
        filename = img_metas[0]['filename']
        img_name = osp.splitext(filename)[0]
        # for eval.
        img_name = img_name.replace('gt_', 'res_')
        imgs = tensor2imgs(img_tensor, **img_norm_cfg)
        assert len(imgs) == len(img_metas)
        img_meta_0 = img_metas[0]
        vs_bbox_result = np.vstack(bbox_result)
        if segm_result is None:
            pred_bboxes, pred_bbox_scores = [], []
        else:
            if isinstance(segm_result, tuple):
                segm_scores = segm_result[-1]
                segms = mmcv.concat_list(segm_result[0])
            else:
                segm_scores = np.asarray(vs_bbox_result[:, -1])
                segms = mmcv.concat_list(segm_result)

            pred_bboxes, pred_bbox_scores = post_processor.process(segms, segm_scores,
                                                       mask_shape=img_meta_0['ori_shape'],
                                                       scale_factor=(1.0, 1.0))
        # save the results.
        single_pred_results = []
        for pred_bbox, pred_bbox_score in zip(pred_bboxes, pred_bbox_scores):
            pred_bbox = np.asarray(pred_bbox).reshape((-1, 2)).astype(np.int32)
            pred_bbox = pred_bbox.tolist()
            single_bbox_dict = {
                "points": pred_bbox,
                "confidence": float(pred_bbox_score)
            }
            single_pred_results.append(single_bbox_dict)
        imgs_bboxes_results[img_name] = single_pred_results

        if show:
            img = cv2.imread(osp.join(img_prefix, filename))
            for idx in range(len(single_pred_results)):
                bbox = np.asarray(single_pred_results[idx]["points"]).reshape(-1, 2).astype(np.int64)
                cv2.drawContours(img, [bbox], -1, (0, 255, 0), 2)
            if debug_f and eval_gt_annotations is not None:
                gt_annos = eval_gt_annotations[img_name]
                for gt_idx in range(len(gt_annos)):
                    gt_bbox = np.asarray(gt_annos[gt_idx]["points"]).reshape(-1, 2).astype(np.int64)
                    if gt_annos[gt_idx]["illegibility"]:
                        # if ignore red
                        color = (255, 0, 0)
                    else:   # if not ignore blue
                        color = (0, 0, 255)
                    cv2.drawContours(img, [gt_bbox], -1, color, 2)
            cv2.imwrite(osp.join(show_path, filename), img)

        batch_size = data['img'][0].size(0)
        for _ in range(batch_size):
            prog_bar.update()
        # print the postmodule pics.
    with open(save_json_file, 'w+', encoding='utf-8') as f:
        json.dump(imgs_bboxes_results, f)


def main():
    args = parse_args()
    test_setting = {}
    if args.out is not None and not args.out.endswith(('.pkl', '.pickle')):
        raise ValueError('The output file must be a pkl file.')

    cfg = mmcv.Config.fromfile(args.config)
    cfg.model.pretrained = None
    cfg.data.test.test_mode = True
    assert osp.isfile(args.test_config), 'Error: wrong path of testing config'
    with open(args.test_config, 'r', encoding='utf-8') as f:
        setting_dict = json.loads(f.read())
        cfg.test_cfg.rcnn.max_per_img = setting_dict["max_per_img"]
        # to modify the test flip ratio
        cfg.data.test.flip_ratio = setting_dict["flip_ratio"]
        # to modify the rcnn iou_thr
        cfg.test_cfg.rcnn.nms.iou_thr = setting_dict['rcnn_iou_thr']
        # to modify the test img scale.
        # cfg.data.test.img_scale = (setting_dict['img_scale_long'], setting_dict['img_scale_short'])
        if len(setting_dict['img_scale']) == 1:
            cfg.data.test.img_scale = tuple(setting_dict['img_scale'][0])
        else:
            cfg.data.test.img_scale = [tuple(setting_dict['img_scale'][i]) for i in range(len(setting_dict['img_scale']))]
        for name, value in setting_dict.items():
            test_setting[name] = value
    dataset = obj_from_dict(cfg.data.test, datasets, dict(test_mode=True))
    # processor = PostProcessor(conf_thr=args.confidence_thr, nms_thr=args.nms_thr)
    processor = PostProcessor(**test_setting)
    if args.gpus == 1:
        model = build_detector(
            cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)
        load_checkpoint(model, args.checkpoint)
        model = MMDataParallel(model, device_ids=[0])

        data_loader = build_dataloader(
            dataset,
            imgs_per_gpu=1,
            workers_per_gpu=cfg.data.workers_per_gpu,
            num_gpus=1,
            dist=False,
            shuffle=False)
        single_test_json(model, data_loader, processor, args.save_json,
                         show=args.show, show_path=args.show_path,
                         debug_f=args.debug, gt_ann_path=args.gt_ann_path)
    else:
        model_args = cfg.model.copy()
        model_args.update(train_cfg=None, test_cfg=cfg.test_cfg)
        model_type = getattr(detectors, model_args.pop('type'))
        outputs = parallel_test_art(
            model_type,
            model_args,
            args.checkpoint,
            dataset,
            _data_func,
            range(args.gpus),
            post_processor=processor,
            save_json_file=args.save_json,
            workers_per_gpu=args.proc_per_gpu,
            show=args.show,
            show_path=args.show_path)


if __name__ == '__main__':
    main()


















